*lethe_cli\Cargo.toml*
```
[package]
name = "lethe_cli"
version = "0.1.0"
edition = "2021"

[dependencies]
# --- Internal Logic ---
lethe_core = { path = "../lethe_core" }

# --- CLI Utilities ---
clap = { version = "4.4", features = ["derive"] } # Command line argument parsing
anyhow = "1.0"      # Error handling
rpassword = "7.0"   # Secure password prompting (masks input)
walkdir = "2.4"     # Recursive directory walking (for 'lethe put')
dirs = "5.0"        # Finding home directories cross-platform
log = "0.4"         # Logging facade
env_logger = "0.10" # Logger implementation
fxhash = "0.2"      # Fast hashing for in-memory maps
humansize = "2.1"

# --- WebDAV Server Stack (The new "Driver") ---
# The core WebDAV logic that handles LS, MKDIR, PUT, GET
dav-server = { version = "0.5", features = ["warp-compat"] }

# The HTTP server that powers the WebDAV drive
warp = "0.3"

# Async runtime required for the server
tokio = { version = "1", features = ["full"] }

# HTTP/Network utilities
headers = "0.3"
bytes = "1"
futures-util = "0.3"
httparse = "1.8"
uuid = { version = "1.6", features = ["v4"] }
rand = "0.9.2"

```

*lethe_cli\src\fs_fuse.rs*
```
use fuser::{
    FileAttr, FileType, Filesystem, ReplyAttr, ReplyData, ReplyDirectory, ReplyEntry,
    ReplyWrite, ReplyCreate, ReplyEmpty, Request, TimeOrNow,
};
use std::ffi::OsStr;
use std::time::{Duration, UNIX_EPOCH, SystemTime};
use std::collections::{HashMap, HashSet};
use lethe_core::index::IndexManager;
use lethe_core::storage::BlockManager;
use lethe_core::crypto::MasterKey;

// --- CROSS PLATFORM ERROR CODES ---
#[cfg(unix)]
use libc::{ENOENT, EACCES, ENOTEMPTY};

#[cfg(windows)]
const ENOENT: i32 = 2;
#[cfg(windows)]
const EACCES: i32 = 13;
#[cfg(windows)]
const ENOTEMPTY: i32 = 39; 

const TTL: Duration = Duration::from_secs(1);

pub struct LetheFS {
    pub index: IndexManager,
    pub storage: BlockManager,
    pub key: MasterKey,
    pub inode_map: HashMap<u64, String>,
    pub write_buffer: HashMap<u64, Vec<u8>>,
}

impl LetheFS {
    // --- HELPER 1: Resolve Path Logic ---
    // Turns (parent_ino, "filename") -> "/path/to/filename"
    fn resolve_path(&self, parent_ino: u64, name: &OsStr) -> Option<String> {
        let parent_path = self.inode_map.get(&parent_ino)?;
        let name_str = name.to_string_lossy();
        
        Some(if parent_path == "/" {
            format!("/{}", name_str)
        } else {
            format!("{}/{}", parent_path, name_str)
        })
    }

    // --- HELPER 2: Generate File Attributes ---
    fn get_file_attr(&self, path: &str, ino: u64) -> FileAttr {
        // 1. Root Directory
        if path == "/" {
            return self.attr_dir(ino);
        }

        // 2. Regular File (In Index)
        if let Some(entry) = self.index.get_file(path) {
            return self.attr_file(ino, entry.size);
        }

        // 3. Regular File (In Write Buffer)
        if let Some(buffer) = self.write_buffer.get(&ino) {
            return self.attr_file(ino, buffer.len() as u64);
        }

        // 4. Implicit Directory (Not in index, but has entry in map)
        // (If logic reached here, it's a directory)
        self.attr_dir(ino)
    }

    fn attr_dir(&self, ino: u64) -> FileAttr {
        FileAttr {
            ino, size: 0, blocks: 0,
            atime: UNIX_EPOCH, mtime: UNIX_EPOCH, ctime: UNIX_EPOCH, crtime: UNIX_EPOCH,
            kind: FileType::Directory, perm: 0o755, nlink: 2, 
            uid: 1000, gid: 1000, rdev: 0, flags: 0, blksize: 512,
        }
    }

    fn attr_file(&self, ino: u64, size: u64) -> FileAttr {
        FileAttr {
            ino, size, blocks: 1,
            atime: UNIX_EPOCH, mtime: UNIX_EPOCH, ctime: UNIX_EPOCH, crtime: UNIX_EPOCH,
            kind: FileType::RegularFile, perm: 0o644, nlink: 1,
            uid: 1000, gid: 1000, rdev: 0, flags: 0, blksize: 512,
        }
    }
}

impl Filesystem for LetheFS {
    // 1. LOOKUP
    fn lookup(&mut self, _req: &Request, parent: u64, name: &OsStr, reply: ReplyEntry) {
        if let Some(path) = self.resolve_path(parent, name) {
            let ino = fxhash::hash64(&path);
            
            // If it exists in map OR buffer, return it
            if self.inode_map.contains_key(&ino) || self.write_buffer.contains_key(&ino) {
                self.inode_map.insert(ino, path.clone()); // Ensure map has it
                reply.entry(&TTL, &self.get_file_attr(&path, ino), 0);
                return;
            }
        }
        reply.error(ENOENT);
    }

    // 2. GET ATTR
    fn getattr(&mut self, _req: &Request, ino: u64, reply: ReplyAttr) {
        if let Some(path) = self.inode_map.get(&ino).cloned() {
            reply.attr(&TTL, &self.get_file_attr(&path, ino));
        } else if ino == 1 {
            reply.attr(&TTL, &self.get_file_attr("/", 1));
        } else {
            reply.error(ENOENT);
        }
    }

    // 3. SET ATTR
    fn setattr(
        &mut self, _req: &Request, ino: u64, _mode: Option<u32>, _uid: Option<u32>, _gid: Option<u32>,
        size: Option<u64>, _atime: Option<TimeOrNow>, _mtime: Option<TimeOrNow>, _ctime: Option<SystemTime>,
        _fh: Option<u64>, _crtime: Option<SystemTime>, _chgtime: Option<SystemTime>, _bkuptime: Option<SystemTime>,
        _flags: Option<u32>, reply: ReplyAttr,
    ) {
        if let Some(path) = self.inode_map.get(&ino).cloned() {
            if let Some(new_size) = size {
                 if let Some(buffer) = self.write_buffer.get_mut(&ino) {
                     buffer.resize(new_size as usize, 0);
                 }
            }
            reply.attr(&TTL, &self.get_file_attr(&path, ino));
        } else {
            reply.error(ENOENT);
        }
    }

    // 4. READ DIR
    fn readdir(&mut self, _req: &Request, ino: u64, _fh: u64, offset: i64, mut reply: ReplyDirectory) {
        let dir_path = match self.inode_map.get(&ino) {
            Some(p) => p.clone(),
            None => { reply.error(ENOENT); return; }
        };

        let mut entries = vec![
            (ino, FileType::Directory, ".".to_string()),
            (ino, FileType::Directory, "..".to_string()),
        ];

        let mut seen = HashSet::new();

        for (child_ino, child_path) in &self.inode_map {
            // Check if child_path is direct child of dir_path
            let is_child = if dir_path == "/" {
                child_path.starts_with('/') && child_path.matches('/').count() == 1
            } else {
                child_path.starts_with(&dir_path) && 
                child_path.len() > dir_path.len() &&
                child_path.chars().nth(dir_path.len()) == Some('/') && 
                child_path[dir_path.len()+1..].matches('/').count() == 0 
            };

            if is_child {
                let name = if dir_path == "/" {
                    child_path.trim_start_matches('/').to_string()
                } else {
                    child_path.strip_prefix(&format!("{}/", dir_path)).unwrap_or("").to_string()
                };

                if !name.is_empty() && !seen.contains(&name) {
                    seen.insert(name.clone());
                    let kind = if self.index.data.files.contains_key(child_path) {
                        FileType::RegularFile
                    } else {
                        FileType::Directory
                    };
                    entries.push((*child_ino, kind, name));
                }
            }
        }

        for (i, (inode, kind, name)) in entries.into_iter().enumerate().skip(offset as usize) {
            if reply.add(inode, (i + 1) as i64, kind, name) { break; }
        }
        reply.ok();
    }

    // 5. CREATE
    fn create(&mut self, _req: &Request, parent: u64, name: &OsStr, _mode: u32, _umask: u32, _flags: i32, reply: ReplyCreate) {
        if let Some(path) = self.resolve_path(parent, name) {
            let ino = fxhash::hash64(&path);
            self.inode_map.insert(ino, path.clone());
            self.write_buffer.insert(ino, Vec::new());
            reply.created(&TTL, &self.get_file_attr(&path, ino), 0, 0, 0);
        } else {
            reply.error(ENOENT);
        }
    }

    // 6. WRITE
    fn write(&mut self, _req: &Request, ino: u64, _fh: u64, offset: i64, data: &[u8], _wflags: u32, _flags: i32, _lock: Option<u64>, reply: ReplyWrite) {
        if let Some(buffer) = self.write_buffer.get_mut(&ino) {
            let end = offset as usize + data.len();
            if end > buffer.len() { buffer.resize(end, 0); }
            buffer[offset as usize..end].copy_from_slice(data);
            reply.written(data.len() as u32);
        } else {
            reply.error(ENOENT);
        }
    }

    // 7. READ
    fn read(&mut self, _req: &Request, ino: u64, _fh: u64, offset: i64, size: u32, _flags: i32, _lock: Option<u64>, reply: ReplyData) {
        // Read from RAM Buffer
        if let Some(buffer) = self.write_buffer.get(&ino) {
             let end = std::cmp::min((offset as u64 + size as u64) as usize, buffer.len());
             if offset as usize >= buffer.len() { reply.data(&[]); } 
             else { reply.data(&buffer[offset as usize..end]); }
             return;
        }
        
        // Read from Disk
        if let Some(path) = self.inode_map.get(&ino) {
             if let Some(entry) = self.index.get_file(path) {
                let mut full_data = Vec::new();
                for block_id in &entry.blocks {
                    if let Ok(mut chunk) = self.storage.read_block(block_id, &self.key) {
                        full_data.append(&mut chunk);
                    }
                }
                let end = std::cmp::min((offset as u64 + size as u64) as usize, full_data.len());
                if offset as usize >= full_data.len() { reply.data(&[]); } 
                else { reply.data(&full_data[offset as usize..end]); }
             } else {
                 reply.error(ENOENT);
             }
        } else {
            reply.error(ENOENT);
        }
    }

    // 8. RELEASE
    fn release(&mut self, _req: &Request, ino: u64, _fh: u64, _flags: i32, _lock: Option<u64>, _flush: bool, reply: ReplyEmpty) {
        if let Some(data) = self.write_buffer.remove(&ino) {
            if let Some(path) = self.inode_map.get(&ino).cloned() {
                if let Ok(block_id) = self.storage.write_block(&data, &self.key) {
                    self.index.add_file(path.clone(), vec![block_id], data.len() as u64);
                    let _ = self.index.save(&self.key);
                }
            }
        }
        reply.ok();
    }

    // 9. UNLINK
    fn unlink(&mut self, _req: &Request, parent: u64, name: &OsStr, reply: ReplyEmpty) {
        if let Some(path) = self.resolve_path(parent, name) {
            if self.index.data.files.remove(&path).is_some() {
                let ino = fxhash::hash64(&path);
                self.inode_map.remove(&ino);
                self.write_buffer.remove(&ino);
                let _ = self.index.save(&self.key);
                reply.ok();
            } else {
                reply.error(ENOENT);
            }
        } else {
            reply.error(ENOENT);
        }
    }

    // 10. RMDIR
    fn rmdir(&mut self, _req: &Request, parent: u64, name: &OsStr, reply: ReplyEmpty) {
        if let Some(dir_path) = self.resolve_path(parent, name) {
            let is_empty = !self.index.data.files.keys().any(|k| {
                 k.starts_with(&dir_path) && k.len() > dir_path.len() && k.chars().nth(dir_path.len()) == Some('/')
            });

            if is_empty {
                let ino = fxhash::hash64(&dir_path);
                self.inode_map.remove(&ino);
                reply.ok();
            } else {
                reply.error(ENOTEMPTY); 
            }
        } else {
            reply.error(ENOENT);
        }
    }

    // 11. RENAME
    fn rename(&mut self, _req: &Request, parent: u64, name: &OsStr, newparent: u64, newname: &OsStr, _flags: u32, reply: ReplyEmpty) {
        let old_path_opt = self.resolve_path(parent, name);
        let new_path_opt = self.resolve_path(newparent, newname);

        if let (Some(old_path), Some(new_path)) = (old_path_opt, new_path_opt) {
            if let Some(entry) = self.index.data.files.remove(&old_path) {
                self.index.data.files.insert(new_path.clone(), entry);
                
                let old_ino = fxhash::hash64(&old_path);
                let new_ino = fxhash::hash64(&new_path);
                self.inode_map.remove(&old_ino);
                self.inode_map.insert(new_ino, new_path);

                let _ = self.index.save(&self.key);
                reply.ok();
            } else {
                reply.error(ENOENT);
            }
        } else {
            reply.error(ENOENT);
        }
    }
}
```

*lethe_cli\src\main.rs*
```
// lethe_cli/src/main.rs
mod dav;
mod cli;

use anyhow::Result;
use clap::Parser;
use cli::{Cli, Commands};

#[tokio::main]
async fn main() -> Result<()> {
    env_logger::Builder::from_env(env_logger::Env::default().default_filter_or("warn")).init();
    let cli = Cli::parse();

    match cli.command {
        Commands::Init { path } => cli::ops::do_init(path),
        Commands::Put { file, dest, vault } => cli::ops::do_put(file, dest, vault),
        Commands::Ls { vault } => cli::ops::do_ls(vault),
        Commands::Get { src, out, vault } => cli::ops::do_get(src, out, vault),
        Commands::Repair { vault } => cli::ops::do_repair(vault),
        Commands::Mount { vault, mountpoint } => cli::mount::do_mount(vault, mountpoint).await,
        Commands::Panic => cli::mount::do_panic(),
        Commands::Clean { vault, dry_run } => cli::ops::do_clean(vault, dry_run),
    }
}
```

*lethe_cli\src\cli\mod.rs*
```
use clap::{Parser, Subcommand};
use std::path::PathBuf;

// --- EXPORT SUBMODULES ---
pub mod ops;
pub mod mount;

#[derive(Parser)]
#[command(name = "lethe", about = "A serverless, encrypted, distributed filesystem.", version = "1.0.0")]
pub struct Cli {
    #[command(subcommand)]
    pub command: Commands,
}

#[derive(Subcommand)]
pub enum Commands {
    Init { 
        #[arg(short, long)] path: Option<String> 
    },
    Put { 
        #[arg(short, long)] file: PathBuf, 
        #[arg(short, long)] dest: String, 
        #[arg(long)] vault: String 
    },
    Ls { 
        #[arg(long)] vault: String 
    },
    Get { 
        #[arg(short, long)] src: String, 
        #[arg(short, long)] out: PathBuf, 
        #[arg(long)] vault: String 
    },
    Mount { 
        #[arg(long)] vault: Option<String>, 
        #[arg(long)] mountpoint: Option<String> 
    },
    Repair { 
        #[arg(long)] vault: String 
    },
    Panic,
    Clean {
        #[arg(long)] vault: String,
        #[arg(long, default_value_t = false)] dry_run: bool,
    },

}
```

*lethe_cli\src\cli\mount.rs*
```
// lethe_cli/src/cli/mount.rs
use anyhow::Result;
use std::sync::Arc;
use std::process::Command;
use log::{error};
use lethe_core::index::IndexManager;
use lethe_core::storage::BlockManager;
use crate::dav::{LetheWebDav, LetheState};
use crate::cli::ops::{resolve_vault_path, unlock_vault};

// Guard to ensure cleanup happens even on panic/ctrl-c
#[cfg(target_os = "windows")]
struct SessionGuard {
    drive: String,
    state: Arc<LetheState>,
}

#[cfg(target_os = "windows")]
impl Drop for SessionGuard {
    fn drop(&mut self) {
        println!("ðŸ§¹ Shutting down session...");
        
        let state = self.state.clone();
        // Force Lock (Wipe Keys from RAM)
        tokio::task::block_in_place(|| {
            tokio::runtime::Handle::current().block_on(async move {
                state.lock().await;
            });
        });
        println!("ðŸ”’ Vault Locked (Keys Wiped).");

        // Unmount
        let _ = Command::new("net")
            .args(&["use", &self.drive, "/delete", "/y"])
            .stdout(std::process::Stdio::null())
            .stderr(std::process::Stdio::null())
            .status();
        println!("âœ… Drive {} unmounted.", self.drive);
    }
}

pub async fn do_mount(vault: Option<String>, mountpoint: Option<String>) -> Result<()> {
    let vault_path = resolve_vault_path(vault.as_deref())?;

    // 1. Initialize Locked State
    let state = Arc::new(LetheState::new());
    println!("ðŸ” Lethe Daemon Initialized.");

    // 2. Unlock
    let (vault_path, key) =
        tokio::task::block_in_place(|| unlock_vault(vault_path.to_str().unwrap()))?;
    let index_mgr = IndexManager::load(vault_path.clone(), &key)?;
    let block_mgr = BlockManager::new(&vault_path)?;

    state.unlock(index_mgr, block_mgr, key).await;
    println!("ðŸ”“ Vault Unlocked.");

    // 3. Start Server
    let lethe_fs = LetheWebDav { state: state.clone() };
    let dav_server = dav_server::DavHandler::builder()
        .filesystem(Box::new(lethe_fs))
        .build_handler();

    let port = 4918;
    let addr = ([127, 0, 0, 1], port);

    let server_handle = tokio::spawn(async move {
        warp::serve(dav_server::warp::dav_handler(dav_server))
            .run(addr)
            .await;
    });

    println!("ðŸš€ Server running at http://127.0.0.1:{}", port);

    // 4. Windows Mount & Guard
    #[cfg(target_os = "windows")]
    {
        let drive_letter = mountpoint.clone().unwrap_or_else(|| "Z:".to_string());
        let _guard = SessionGuard {
            drive: drive_letter.clone(),
            state: state.clone(),
        };

        let _ = Command::new("net")
            .args(&["use", &drive_letter, "/delete", "/y"])
            .status();

        let status = Command::new("net")
            .args(&["use", &drive_letter, &format!("http://127.0.0.1:{}", port)])
            .status()?;

        if status.success() {
            println!("âœ… Mounted to {}.", drive_letter);
            let rename = format!(
                "$sh = New-Object -ComObject Shell.Application; \
                 $sh.NameSpace('{}').Self.Name = 'Lethe Vault'",
                drive_letter
            );
            let _ = Command::new("powershell")
                .args(&["-NoProfile", "-Command", &rename])
                .status();
            let _ = Command::new("explorer").arg(&drive_letter).spawn();
        } else {
            error!("Mount failed.");
            return Ok(());
        }

        println!("running... (Press Ctrl+C to Lock & Quit)");
        tokio::signal::ctrl_c().await?;
        println!("\nðŸ›‘ Shutdown signal received.");
    }

    // --- LINUX / MACOS MOUNT ---
    #[cfg(not(target_os = "windows"))]
    {
        println!("ðŸ§ Unix-like OS detected.");
        let url = format!("dav://127.0.0.1:{}", port);
        let http_url = format!("http://127.0.0.1:{}", port);

        // Try to open with system handler
        #[cfg(target_os = "linux")]
        {
            println!("   Opening File Manager (xdg-open)...");
            // Linux typically uses dav:// scheme for GVFS/KIO
            if Command::new("xdg-open").arg(&url).spawn().is_err() {
                eprintln!(
                    "âš ï¸  Could not auto-open file manager. Manually connect to: {}",
                    url
                );
            }
        }

        #[cfg(target_os = "macos")]
        {
            println!("ðŸŽ macOS detected. Mounting volume...");
            // macOS uses 'open' with http/https url to mount WebDAV in Finder
            if Command::new("open").arg(&http_url).spawn().is_err() {
                eprintln!(
                    "âš ï¸  Could not auto-mount. In Finder, Go > Connect to Server > {}",
                    http_url
                );
            }
        }

        println!("âœ… Server is active.");
        println!("   WebDAV URL: {}", http_url);
        println!("   (Press Ctrl+C to unmount and exit)");

        // Wait for shutdown signal
        tokio::signal::ctrl_c().await?;
        println!("\nðŸ›‘ Shutdown signal received. Stopping server...");
    }

    server_handle.abort();
    Ok(())
}


pub fn do_panic() -> Result<()> {
    #[cfg(target_os = "windows")]
    for drive in ["Z:", "Y:", "X:"] {
        let _ = Command::new("net").args(&["use", drive, "/delete", "/y"]).status();
    }
    Ok(())
}
```

*lethe_cli\src\cli\ops.rs*
```
// lethe_cli/src/cli/ops.rs

use anyhow::{anyhow, Context, Result};
use log::error;
use std::fs;
use std::io::{self, Write};
use std::path::{Path, PathBuf};
use walkdir::WalkDir;

use lethe_core::crypto::{CryptoEngine, MasterKey};
use lethe_core::index::IndexManager;
use lethe_core::storage::BlockManager;

// Add these imports at the top
use std::collections::HashSet;
use std::ffi::OsStr;

// --- SHARED HELPERS ---

pub fn resolve_vault_path(path: Option<&str>) -> Result<PathBuf> {
    match path {
        Some(p) => Ok(PathBuf::from(p)),
        None => dirs::home_dir()
            .map(|p| p.join(".lethe_vault"))
            .context("Could not determine home directory"),
    }
}

pub fn unlock_vault(vault_path_str: &str) -> Result<(PathBuf, MasterKey)> {
    let vault_path = resolve_vault_path(Some(vault_path_str))?;
    let salt_path = vault_path.join("salt.loader");

    if !salt_path.exists() {
        anyhow::bail!(
            "Invalid vault path: {:?}. (Did you run 'lethe init'?)",
            vault_path
        );
    }

    let password = rpassword::prompt_password("Enter Vault Password: ")?;
    let salt = fs::read_to_string(salt_path).context("Failed to read salt file")?;

    let (key, _) = CryptoEngine::derive_key_with_salt(&password, salt.trim())?;
    Ok((vault_path, key))
}

fn upload_worker(
    path: &Path,
    dest: &str,
    block_mgr: &BlockManager,
    index_mgr: &mut IndexManager,
    key: &MasterKey,
) -> Result<()> {
    print!("Processing {} ... ", path.display());
    io::stdout().flush()?;

    let data = fs::read(path).context("Failed to read source file")?;
    let size = data.len() as u64;

    // Note: This is still the "simple" upload.
    // Ideally this should use the chunking logic too, but it's acceptable for CLI tool v1.
    let block_id = block_mgr.write_block(&data, key)?;

    let clean_dest = dest.replace("//", "/");
    index_mgr.add_file(clean_dest, vec![block_id], size);

    println!("OK");
    Ok(())
}

// --- COMMAND HANDLERS ---

pub fn do_init(path: Option<String>) -> Result<()> {
    let vault_path = resolve_vault_path(path.as_deref())?;
    if vault_path.exists() {
        anyhow::bail!("Vault already exists at {:?}", vault_path);
    }

    println!("ðŸ›¡ï¸  Initializing vault at: {:?}", vault_path);

    let password = rpassword::prompt_password("Set Master Password: ")?;
    let confirm = rpassword::prompt_password("Confirm Password: ")?;

    if password != confirm {
        anyhow::bail!("Passwords do not match.");
    }
    if password.is_empty() {
        anyhow::bail!("Password cannot be empty.");
    }

    fs::create_dir_all(&vault_path).context("Failed to create vault directory")?;

    println!("ðŸ”‘ Generating keys (Argon2id)...");

    let (key, salt) = tokio::task::block_in_place(|| CryptoEngine::derive_key(&password))?;
    fs::write(vault_path.join("salt.loader"), &salt).context("Failed to write salt")?;

    let mut index_mgr = IndexManager::new_empty(vault_path.clone(), salt);
    index_mgr.save(&key)?;

    let _ = BlockManager::new(&vault_path)?;

    println!("âœ… Vault initialized successfully.");
    Ok(())
}

pub fn do_put(file: PathBuf, dest: String, vault: String) -> Result<()> {
    let (vault_path, key) = tokio::task::block_in_place(|| unlock_vault(&vault))?;
    let mut index_mgr = IndexManager::load(vault_path.clone(), &key)?;
    let block_mgr = BlockManager::new(&vault_path)?;

    if !file.exists() {
        anyhow::bail!("Source file not found: {:?}", file);
    }

    if file.is_dir() {
        println!("ðŸ“‚ Uploading directory: {:?}", file);

        for entry in WalkDir::new(&file).min_depth(1) {
            let entry = entry?;
            if entry.file_type().is_file() {
                let path = entry.path();
                let relative = path.strip_prefix(&file)?;
                let clean_relative = relative.to_string_lossy().replace("\\", "/");

                let clean_dest = dest.trim_end_matches('/');
                let vault_dest = format!("{}/{}", clean_dest, clean_relative);

                upload_worker(path, &vault_dest, &block_mgr, &mut index_mgr, &key)?;
            }
        }
    } else {
        upload_worker(&file, &dest, &block_mgr, &mut index_mgr, &key)?;
    }

    index_mgr.save(&key)?;
    println!("âœ… Upload complete.");
    Ok(())
}

pub fn do_ls(vault: String) -> Result<()> {
    let (vault_path, key) = tokio::task::block_in_place(|| unlock_vault(&vault))?;
    let index_mgr = IndexManager::load(vault_path, &key)?;

    println!("\nðŸ“‚ Vault Contents:");
    println!("{:<12} | {:<40}", "SIZE", "PATH");
    println!("{:-<60}", "-");

    let mut paths: Vec<_> = index_mgr.data.files.keys().collect();
    paths.sort();

    for path in paths {
        let entry = &index_mgr.data.files[path];
        let size_str = humansize::format_size(entry.size, humansize::BINARY);
        println!("{:<12} | {}", size_str, path);
    }

    println!();
    Ok(())
}

pub fn do_get(src: String, out: PathBuf, vault: String) -> Result<()> {
    let (vault_path, key) = tokio::task::block_in_place(|| unlock_vault(&vault))?;
    let index_mgr = IndexManager::load(vault_path.clone(), &key)?;
    let block_mgr = BlockManager::new(&vault_path)?;

    if let Some(entry) = index_mgr.get_file(&src) {
        println!(
            "ðŸ“¥ Downloading {} ({})",
            src,
            humansize::format_size(entry.size, humansize::BINARY)
        );

        let mut full_data = Vec::with_capacity(entry.size as usize);
        for block_id in &entry.blocks {
            let mut chunk = block_mgr.read_block(block_id, &key)?;
            full_data.append(&mut chunk);
        }

        if let Some(parent) = out.parent() {
            fs::create_dir_all(parent)?;
        }

        fs::write(&out, full_data)?;
        println!("âœ… Saved to {:?}", out);
    } else {
        anyhow::bail!("File not found in vault: {}", src);
    }

    Ok(())
}

pub fn do_repair(vault: String) -> Result<()> {
    println!("ðŸ› ï¸  Starting repair process...");

    let (vault_path, key) = tokio::task::block_in_place(|| unlock_vault(&vault))?;

    match IndexManager::load(vault_path, &key) {
        Ok(mut index_mgr) => {
            println!(
                "âœ… Valid index replica found (Rev: {}).",
                index_mgr.data.revision
            );
            println!("ðŸ”„ Resyncing all replicas...");
            index_mgr.save(&key)?;
            println!("âœ… Repair complete.");
            Ok(())
        }
        Err(e) => {
            error!("Repair failed: {}", e);
            anyhow::bail!("CRITICAL: Could not recover index. Vault may be corrupted.");
        }
    }
}

// ... (existing functions) ...

pub fn do_clean(vault: String, dry_run: bool) -> Result<()> {
    println!("ðŸ§¹ Starting Garbage Collection...");
    if dry_run {
        println!("â„¹ï¸  DRY RUN: No files will be deleted.");
    }

    // 1. Unlock and Load Index
    let (vault_path, key) = tokio::task::block_in_place(|| unlock_vault(&vault))?;
    let index_mgr = IndexManager::load(vault_path.clone(), &key)?;

    // 2. Build Set of Valid Blocks
    println!("ðŸ“Š Analyzing Index...");
    let mut valid_blocks = HashSet::new();
    for entry in index_mgr.data.files.values() {
        for block in &entry.blocks {
            valid_blocks.insert(block.clone());
        }
    }
    println!(
        "   Found {} active blocks referenced in Index.",
        valid_blocks.len()
    );

    // 3. Scan Disk for Orphans
    let mut reclaimed_bytes: u64 = 0;
    let mut deleted_count: u64 = 0;
    let mut kept_count: u64 = 0;

    // Assuming blocks are stored directly in vault_path or vault_path/store
    // We scan the vault_path for blk_*.bin files
    let read_dir = fs::read_dir(&vault_path).context("Failed to read vault directory")?;

    for entry in read_dir {
        let entry = entry?;
        let path = entry.path();

        // Filter for files starting with "blk_" and ending with ".bin"
        if path.is_file() {
            if let Some(name) = path.file_name().and_then(OsStr::to_str) {
                if name.starts_with("blk_") && name.ends_with(".bin") {
                    // Extract ID: blk_XYZ.bin -> XYZ
                    let id_part = &name[4..name.len() - 4];

                    if !valid_blocks.contains(id_part) {
                        // ORPHAN DETECTED
                        let len = entry.metadata()?.len();
                        if !dry_run {
                            fs::remove_file(&path)
                                .context("Failed to delete orphan block")?;
                        }
                        reclaimed_bytes += len;
                        deleted_count += 1;

                        if dry_run {
                            println!("   [DRY] Would delete orphan: {}", name);
                        }
                    } else {
                        kept_count += 1;
                    }
                }
            }
        }
    }

    println!("---------------------------------------------------");
    println!("âœ… GC Complete.");
    println!("   Active Blocks: {}", kept_count);
    println!("   Orphans Removed: {}", deleted_count);
    println!(
        "   Space Reclaimed: {}",
        humansize::format_size(reclaimed_bytes, humansize::BINARY)
    );

    Ok(())
}

```

*lethe_cli\src\dav\file.rs*
```
// lethe_cli/src/dav/file.rs
use std::io::{Cursor, Read, Seek, SeekFrom, Write};
use std::sync::Arc;
use std::time::{SystemTime};
use std::path::PathBuf;
use std::fs;
use bytes::{Buf, Bytes};
use dav_server::fs::{DavFile, DavMetaData, FsError, FsFuture};
use lethe_core::storage::BlockManager;
use lethe_core::crypto::MasterKey;
use lethe_core::index::IndexManager;
use tokio::sync::Mutex;
use uuid::Uuid;

use super::locks::WriteGuard;

// Config: 64KB Blocks
const BLOCK_SIZE: usize = 65536;

#[derive(Debug, Clone)]
pub struct LetheFileMetaData {
    pub len: u64,
    pub modified: SystemTime,
    pub is_dir: bool,
    pub etag: String,
}

impl DavMetaData for LetheFileMetaData {
    fn len(&self) -> u64 { self.len }
    fn modified(&self) -> Result<SystemTime, FsError> { Ok(self.modified) }
    fn is_dir(&self) -> bool { self.is_dir }
    fn etag(&self) -> Option<String> { Some(self.etag.clone()) }
}

// Thread-safe container for the file buffer
#[derive(Debug)]
struct FileState {
    buffer: Cursor<Vec<u8>>, // Uses Standard Library Cursor for robust seek/write
    is_dirty: bool,
}

#[derive(Debug)] // removed Clone derived, DavFile doesn't require Clone, and WriteGuard is not Clone
pub struct LetheDavFile {
    pub index: Arc<Mutex<IndexManager>>,
    pub storage: Arc<BlockManager>,
    pub key: Arc<MasterKey>,
    pub path: String,
    pub vault_root: PathBuf,
    
    // Thread-safe state wrapper
    state: Arc<Mutex<FileState>>,

    // NEW: Optional Write Guard.
    // If this is Some, we hold the lock. When dropped, lock releases.
    pub write_guard: Option<WriteGuard>, 
}

impl LetheDavFile {
    pub fn new(
        index: Arc<Mutex<IndexManager>>,
        storage: Arc<BlockManager>,
        key: Arc<MasterKey>,
        path: String,
        vault_root: PathBuf,
        initial_data: Vec<u8>,
        // Accept the guard
        write_guard: Option<WriteGuard>, 
    ) -> Self {
        Self {
            index,
            storage,
            key,
            path,
            vault_root,
            state: Arc::new(Mutex::new(FileState {
                buffer: Cursor::new(initial_data),
                is_dirty: false,
            })),
            write_guard,
        }
    }
}

impl DavFile for LetheDavFile {
    fn read_bytes(&mut self, count: usize) -> FsFuture<Bytes> {
        let state_arc = self.state.clone();
        Box::pin(async move {
            let mut state = state_arc.lock().await;
            let mut buf = vec![0u8; count];
            match state.buffer.read(&mut buf) {
                Ok(n) => {
                    buf.truncate(n);
                    Ok(Bytes::from(buf))
                }
                Err(_) => Err(FsError::GeneralFailure),
            }
        })
    }

    fn write_buf(&mut self, mut buf: Box<dyn Buf + Send>) -> FsFuture<()> {
        let mut chunk = vec![0u8; buf.remaining()];
        buf.copy_to_slice(&mut chunk);
        let state_arc = self.state.clone();

        Box::pin(async move {
            let mut state = state_arc.lock().await;
            match state.buffer.write_all(&chunk) {
                Ok(_) => {
                    state.is_dirty = true;
                    Ok(())
                }
                Err(_) => Err(FsError::GeneralFailure),
            }
        })
    }

    fn write_bytes(&mut self, buf: Bytes) -> FsFuture<()> {
        self.write_buf(Box::new(buf))
    }

    fn seek(&mut self, pos: SeekFrom) -> FsFuture<u64> {
        let state_arc = self.state.clone();
        Box::pin(async move {
            let mut state = state_arc.lock().await;
            state.buffer.seek(pos).map_err(|_| FsError::GeneralFailure)
        })
    }

    fn flush(&mut self) -> FsFuture<()> {
        let path = self.path.clone();
        let index_arc = self.index.clone();
        let key_arc = self.key.clone();
        let storage = self.storage.clone();
        let vault_root = self.vault_root.clone();
        let state_arc = self.state.clone();

        Box::pin(async move {
            let mut state = state_arc.lock().await;
            
            // Only save if modified (optimization)
            if !state.is_dirty { return Ok(()); }

            // 1. CHUNKING LOGIC
            // Split the single RAM buffer into 64KB blocks
            let full_data = state.buffer.get_ref();
            let total_size = full_data.len() as u64;
            let mut new_block_ids = Vec::new();

            for chunk in full_data.chunks(BLOCK_SIZE) {
                // Compress/Encrypt/Write each chunk
                let block_id = storage.write_block(chunk, &key_arc)
                    .map_err(|_| FsError::GeneralFailure)?;
                new_block_ids.push(block_id);
            }

            // 2. WAL (JOURNAL) LOGIC
            // Write a "pending" file to disk before updating the index
            let journal_dir = vault_root.join("journal");
            let _ = fs::create_dir_all(&journal_dir);
            let tx_id = Uuid::new_v4();
            let journal_path = journal_dir.join(format!("tx_{}.pending", tx_id));
            
            let block_str = new_block_ids.join(",");
            let journal_content = format!("{}|{}|{}", path, block_str, total_size);

            if fs::write(&journal_path, journal_content).is_err() {
                // If we can't journal, we abort to stay safe
                return Err(FsError::GeneralFailure);
            }

            // 3. UPDATE INDEX
            let mut idx = index_arc.lock().await;
            idx.add_file(path.clone(), new_block_ids, total_size);

            if idx.save(&key_arc).is_err() {
                return Err(FsError::GeneralFailure);
            }

            // 4. CLEANUP JOURNAL
            let _ = fs::remove_file(journal_path);
            
            // Reset dirty flag
            state.is_dirty = false;
            Ok(())
        })
    }

    fn metadata(&mut self) -> FsFuture<Box<dyn DavMetaData>> {
        let state_arc = self.state.clone();
        Box::pin(async move {
            let state = state_arc.lock().await;
            let len = state.buffer.get_ref().len() as u64;
            
            Ok(Box::new(LetheFileMetaData {
                len,
                modified: SystemTime::now(),
                is_dir: false,
                etag: format!("\"mem-{:x}\"", len),
            }) as Box<dyn DavMetaData>)
        })
    }
}
```

*lethe_cli\src\dav\fs.rs*
```
use super::file::LetheDavFile;
use crate::dav::state::LetheState;
use dav_server::fs::{
    DavFileSystem, DavFile, DavDirEntry, FsFuture, FsError, OpenOptions, ReadDirMeta,
};
use dav_server::davpath::DavPath;
use std::sync::Arc;
use std::time::UNIX_EPOCH;
use futures_util::stream;
use super::LetheDavDirEntry;

use tokio::time::Duration;

#[derive(Clone)]
pub struct LetheWebDav {
    pub state: Arc<LetheState>,
}

impl DavFileSystem for LetheWebDav {
    fn open<'a>(&'a self, path: &'a DavPath, options: OpenOptions) -> FsFuture<Box<dyn DavFile>> {
        let path_str = path.as_pathbuf().to_string_lossy().replace("\\", "/");
        let state = self.state.clone();

        Box::pin(async move {
            let guard = state.get_resources().await.ok_or(FsError::Forbidden)?;
            let vault_root = guard.index.lock().await.root_path().clone();

            // 1. LOCKING (Concurrency Safety)
            let write_guard = if options.write {
                Some(guard.locks.try_lock(path_str.clone())?)
            } else {
                None
            };

            let mut index = guard.index.lock().await;

            // 2. IMMEDIATE CREATE STRATEGY (Fixes 0x8000FFFF)
            // If opening for write and file doesn't exist, create 0-byte entry NOW.
            if options.write && index.get_file(&path_str).is_none() {
                // We create a valid, empty file entry in the index
                index.add_file(path_str.clone(), Vec::new(), 0);
                index.save(&guard.key).map_err(|_| FsError::GeneralFailure)?;
            }

            // 3. LOAD DATA
            if let Some(entry) = index.get_file(&path_str) {
                if entry.is_dir { return Err(FsError::Forbidden); }

                let mut data = Vec::with_capacity(entry.size as usize);
                
                // If Truncate is ON (Overwriting file), we start empty.
                // Otherwise (Reading/Appending), we load the blocks.
                if !options.truncate {
                    for block_id in &entry.blocks {
                        if let Ok(mut chunk) = guard.storage.read_block(block_id, &guard.key) {
                            data.append(&mut chunk);
                        }
                    }
                }

                Ok(Box::new(LetheDavFile::new(
                    guard.index.clone(),
                    guard.storage.clone(),
                    guard.key.clone(),
                    path_str,
                    vault_root,
                    data,
                    write_guard, // Pass the lock
                )) as Box<dyn DavFile>)

            } else {
                // Should be unreachable due to Immediate Create, but safe fallback
                Err(FsError::NotFound)
            }
        })
    }


    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 2. READ DIRECTORY
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fn read_dir<'a>(
        &'a self,
        path: &'a DavPath,
        _meta: ReadDirMeta,
    ) -> FsFuture<dav_server::fs::FsStream<Box<dyn DavDirEntry>>> {
        let path_str = path.as_pathbuf().to_string_lossy().replace("\\", "/");
        let state = self.state.clone();

        Box::pin(async move {
            let guard = state.get_resources().await.ok_or(FsError::Forbidden)?;
            let index = guard.index.lock().await;

            let mut entries = Vec::new();
            let mut seen = std::collections::HashSet::new();

            for full_path in index.data.files.keys() {
                if let Some(rest) = full_path.strip_prefix(&path_str) {
                    let rest = rest.trim_start_matches('/');
                    if rest.is_empty() {
                        continue;
                    }

                    let name = rest.split('/').next().unwrap();
                    if !seen.insert(name.to_string()) {
                        continue;
                    }

                    let full_child =
                        format!("{}/{}", path_str.trim_end_matches('/'), name);

                    let meta = if let Some(e) = index.get_file(&full_child) {
                        super::file::LetheFileMetaData {
                            len: e.size,
                            modified: UNIX_EPOCH + Duration::from_secs(e.modified),
                            is_dir: e.is_dir,
                            etag: format!("\"{:x}-{:x}\"", e.size, e.modified),
                        }
                    } else {
                        super::file::LetheFileMetaData {
                            len: 0,
                            modified: UNIX_EPOCH,
                            is_dir: true,
                            etag: format!("\"dir-{}\"", fxhash::hash64(name)),
                        }
                    };

                    entries.push(Box::new(LetheDavDirEntry {
                        name: name.to_string(),
                        meta,
                    }) as Box<dyn DavDirEntry>);
                }
            }

            Ok(Box::pin(stream::iter(entries))
                as dav_server::fs::FsStream<Box<dyn DavDirEntry>>)

        })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 3. METADATA
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fn metadata<'a>(
        &'a self,
        path: &'a DavPath,
    ) -> FsFuture<Box<dyn dav_server::fs::DavMetaData>> {
        let path_str = path.as_pathbuf().to_string_lossy().replace("\\", "/");
        let state = self.state.clone();

        Box::pin(async move {
            let guard = state.get_resources().await.ok_or(FsError::Forbidden)?;
            let index = guard.index.lock().await;

            if path_str == "/" {
                return Ok(Box::new(super::file::LetheFileMetaData {
                    len: 0,
                    modified: UNIX_EPOCH,
                    is_dir: true,
                    etag: "\"root\"".into(),
                }) as Box<dyn dav_server::fs::DavMetaData>);
            }

            if let Some(e) = index.get_file(&path_str) {
                return Ok(Box::new(super::file::LetheFileMetaData {
                    len: e.size,
                    modified: UNIX_EPOCH + Duration::from_secs(e.modified),
                    is_dir: e.is_dir,
                    etag: format!("\"{:x}-{:x}\"", e.size, e.modified),
                }));
            }

            let is_dir = index
                .data
                .files
                .keys()
                .any(|k| k.starts_with(&format!("{}/", path_str)));

            if is_dir {
                return Ok(Box::new(super::file::LetheFileMetaData {
                    len: 0,
                    modified: UNIX_EPOCH,
                    is_dir: true,
                    etag: format!(
                        "\"implicit-{}\"",
                        fxhash::hash64(&path_str)
                    ),
                }));
            }

            Err(FsError::NotFound)
        })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 4â€“7. WRITE OPS (unchanged semantics)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fn create_dir<'a>(&'a self, path: &'a DavPath) -> FsFuture<()> {
        let path = path.as_pathbuf().to_string_lossy().replace("\\", "/");
        let state = self.state.clone();

        Box::pin(async move {
            let guard = state.get_resources().await.ok_or(FsError::Forbidden)?;
            let mut index = guard.index.lock().await;

            if index.get_file(&path).is_some() {
                return Err(FsError::Exists);
            }

            index.add_dir(path);
            index.save(&guard.key).map_err(|_| FsError::GeneralFailure)?;
            Ok(())
        })
    }

    fn remove_dir<'a>(&'a self, path: &'a DavPath) -> FsFuture<()> {
        let path = path.as_pathbuf().to_string_lossy().replace("\\", "/");
        let state = self.state.clone();

        Box::pin(async move {
            let guard = state.get_resources().await.ok_or(FsError::Forbidden)?;
            let mut index = guard.index.lock().await;

            if index.data.files.keys().any(|k| k.starts_with(&format!("{}/", path))) {
                return Err(FsError::Forbidden);
            }

            index.data.files.remove(&path).ok_or(FsError::NotFound)?;
            index.save(&guard.key).map_err(|_| FsError::GeneralFailure)?;
            Ok(())
        })
    }

    fn remove_file<'a>(&'a self, path: &'a DavPath) -> FsFuture<()> {
        let path = path.as_pathbuf().to_string_lossy().replace("\\", "/");
        let state = self.state.clone();

        Box::pin(async move {
            let guard = state.get_resources().await.ok_or(FsError::Forbidden)?;
            let mut index = guard.index.lock().await;

            index.data.files.remove(&path).ok_or(FsError::NotFound)?;
            index.save(&guard.key).map_err(|_| FsError::GeneralFailure)?;
            Ok(())
        })
    }

    fn rename<'a>(
        &'a self,
        from: &'a DavPath,
        to: &'a DavPath,
    ) -> FsFuture<()> {
        let from = from.as_pathbuf().to_string_lossy().replace("\\", "/");
        let to = to.as_pathbuf().to_string_lossy().replace("\\", "/");
        let state = self.state.clone();

        Box::pin(async move {
            let guard = state.get_resources().await.ok_or(FsError::Forbidden)?;
            let mut index = guard.index.lock().await;

            let keys: Vec<_> = index
                .data
                .files
                .keys()
                .filter(|k| *k == &from || k.starts_with(&format!("{}/", from)))
                .cloned()
                .collect();

            if keys.is_empty() {
                return Err(FsError::NotFound);
            }

            for old in keys {
                if let Some(mut e) = index.data.files.remove(&old) {
                    let suffix = old.strip_prefix(&from).unwrap_or("");
                    let new = format!("{}{}", to, suffix);
                    e.path = new.clone();
                    index.data.files.insert(new, e);
                }
            }

            index.save(&guard.key).map_err(|_| FsError::GeneralFailure)?;
            Ok(())
        })
    }
}
```

*lethe_cli\src\dav\locks.rs*
```
// lethe_cli/src/dav/locks.rs
use std::sync::{Arc, Mutex};
use std::collections::HashSet;
use dav_server::fs::FsError;

/// Simple in-memory lock manager to enforce single-writer consistency.
#[derive(Debug, Clone)]
pub struct LockManager {
    // Stores the paths currently open for WRITING
    active_writes: Arc<Mutex<HashSet<String>>>,
}

impl LockManager {
    pub fn new() -> Self {
        Self {
            active_writes: Arc::new(Mutex::new(HashSet::new())),
        }
    }

    /// Tries to acquire a write lock for a path.
    /// Returns a guard that releases the lock when dropped.
    pub fn try_lock(&self, path: String) -> Result<WriteGuard, FsError> {
        let mut locks = self.active_writes.lock().map_err(|_| FsError::GeneralFailure)?;
        
        if locks.contains(&path) {
            // File is already open for writing!
            return Err(FsError::Forbidden);

        }

        locks.insert(path.clone());
        Ok(WriteGuard {
            path,
            manager: self.active_writes.clone(),
        })
    }
}

/// RAII Guard: Automatically unlocks the path when the File handle is dropped.
#[derive(Debug)]
pub struct WriteGuard {
    path: String,
    manager: Arc<Mutex<HashSet<String>>>,
}

impl Drop for WriteGuard {
    fn drop(&mut self) {
        if let Ok(mut locks) = self.manager.lock() {
            locks.remove(&self.path);
        }
    }
}
```

*lethe_cli\src\dav\mod.rs*
```
pub mod fs;
pub mod file;
pub mod state;
pub mod locks;

pub use fs::LetheWebDav;
pub use state::LetheState;

use dav_server::fs::{DavDirEntry, DavMetaData, FsFuture};
use self::file::LetheFileMetaData;

// --- INLINE DIRECTORY ENTRY STRUCT ---
pub struct LetheDavDirEntry {
    pub name: String,
    pub meta: LetheFileMetaData,
}

impl DavDirEntry for LetheDavDirEntry {
    fn name(&self) -> Vec<u8> {
        self.name.as_bytes().to_vec()
    }

    fn metadata(&self) -> FsFuture<Box<dyn DavMetaData>> {
        let m = self.meta.clone();
        Box::pin(async move { Ok(Box::new(m) as Box<dyn DavMetaData>) })
    }
}
```

*lethe_cli\src\dav\state.rs*
```
// lethe_cli/src/dav/state.rs
use std::sync::Arc;
use tokio::sync::{RwLock, Mutex};
use lethe_core::index::IndexManager;
use lethe_core::storage::BlockManager;
use lethe_core::crypto::MasterKey;
use super::locks::LockManager; // <--- Import

pub struct ActiveVault {
    pub index: Arc<Mutex<IndexManager>>,
    pub storage: Arc<BlockManager>,
    pub key: Arc<MasterKey>,
    pub locks: LockManager, // <--- Add this field
}

pub struct LetheState {
    inner: RwLock<Option<ActiveVault>>,
}

impl LetheState {
    pub fn new() -> Self {
        Self { inner: RwLock::new(None) }
    }

    pub async fn unlock(&self, index: IndexManager, storage: BlockManager, key: MasterKey) {
        let mut write_guard = self.inner.write().await;
        *write_guard = Some(ActiveVault {
            index: Arc::new(Mutex::new(index)),
            storage: Arc::new(storage),
            key: Arc::new(key),
            locks: LockManager::new(), // <--- Initialize new locks
        });
    }

    pub async fn lock(&self) {
        let mut write_guard = self.inner.write().await;
        *write_guard = None; // Wipes keys/index/locks from RAM
    }

    pub async fn get_resources(&self) -> Option<ActiveVault> {
        let read_guard = self.inner.read().await;
        match &*read_guard {
            Some(v) => Some(ActiveVault {
                index: v.index.clone(),
                storage: v.storage.clone(),
                key: v.key.clone(),
                locks: v.locks.clone(),
            }),
            None => None,
        }
    }
}
```

*lethe_core\Cargo.toml*
```
[package]
name = "lethe_core"
version = "0.1.0"
edition = "2021"

[dependencies]
# --- Serialization (Saving the Index) ---
serde = { version = "1.0", features = ["derive"] }
serde_cbor = "0.11" # Binary format for index files (smaller/faster than JSON)

# --- Cryptography (The Security Layer) ---
# XChaCha20-Poly1305: Authenticated Encryption (better than AES-GCM for this)
chacha20poly1305 = "0.10" 

# Argon2: State-of-the-art password hashing for deriving the MasterKey
argon2 = "0.5" 

# Randomness for salts and nonces
rand = "0.8"

# Clears memory on drop (prevents password from staying in RAM)
zeroize = { version = "1.7", features = ["derive"] }

# --- Compression ---
# Zstandard: High compression ratio, very fast decompression
zstd = "0.13"

# --- Utilities ---
uuid = { version = "1.6", features = ["v4", "serde"] } # For block IDs
anyhow = "1.0"
thiserror = "1.0"
```

*lethe_core\src\config.rs*
```
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VaultConfig {
    /// Size of each block in bytes (default: 65536)
    pub block_size: usize,
    /// Zstd compression level (1-22)
    pub compression_level: i32,
}

impl Default for VaultConfig {
    fn default() -> Self {
        Self {
            block_size: 65536, // 64KB
            compression_level: 3,
        }
    }
}
```

*lethe_core\src\crypto.rs*
```
use chacha20poly1305::{
    aead::{Aead, KeyInit},
    XChaCha20Poly1305, XNonce
};
use argon2::{
    password_hash::{rand_core::OsRng, SaltString},
    Argon2, PasswordHasher
};
use rand::RngCore;
use zeroize::{Zeroize, ZeroizeOnDrop};
use anyhow::{Result, Context};

const KEY_SIZE: usize = 32;
const NONCE_SIZE: usize = 24;

#[derive(Zeroize, ZeroizeOnDrop, Debug)]
pub struct MasterKey {
    key: [u8; KEY_SIZE],
}

impl MasterKey {
    pub fn new(bytes: [u8; KEY_SIZE]) -> Self {
        Self { key: bytes }
    }
    
    pub fn as_bytes(&self) -> &[u8; KEY_SIZE] {
        &self.key
    }
}

pub struct CryptoEngine;

impl CryptoEngine {
    /// Generates a NEW salt and derives a key (For "Init")
    pub fn derive_key(password: &str) -> Result<(MasterKey, String)> {
        let salt = SaltString::generate(&mut OsRng);
        Self::derive_internal(password, &salt)
    }

    /// Uses an EXISTING salt to derive the key (For "Unlock")
    pub fn derive_key_with_salt(password: &str, salt_str: &str) -> Result<(MasterKey, String)> {
        let salt = SaltString::from_b64(salt_str)
            .map_err(|e| anyhow::anyhow!("Invalid salt format: {}", e))?;
        Self::derive_internal(password, &salt)
    }

    fn derive_internal(password: &str, salt: &SaltString) -> Result<(MasterKey, String)> {
        let argon2 = Argon2::default();
        let password_hash = argon2.hash_password(password.as_bytes(), salt)
            .map_err(|e| anyhow::anyhow!(e))?;

        let output = password_hash.hash.context("Argon2 hashing failed")?;
        
        if output.len() < KEY_SIZE {
            return Err(anyhow::anyhow!("Argon2 output too short"));
        }
        
        let mut key_bytes = [0u8; KEY_SIZE];
        key_bytes.copy_from_slice(&output.as_bytes()[..KEY_SIZE]);
        
        Ok((MasterKey::new(key_bytes), salt.as_str().to_string()))
    }

    pub fn encrypt(data: &[u8], key: &MasterKey) -> Result<(Vec<u8>, Vec<u8>)> {
        let cipher = XChaCha20Poly1305::new(key.as_bytes().into());
        let mut nonce_bytes = [0u8; NONCE_SIZE];
        OsRng.fill_bytes(&mut nonce_bytes);
        let nonce = XNonce::from_slice(&nonce_bytes);

        let ciphertext = cipher.encrypt(nonce, data)
            .map_err(|_| anyhow::anyhow!("Encryption failure"))?;
        
        Ok((ciphertext, nonce_bytes.to_vec()))
    }

    pub fn decrypt(ciphertext: &[u8], nonce: &[u8], key: &MasterKey) -> Result<Vec<u8>> {
        if nonce.len() != NONCE_SIZE {
            return Err(anyhow::anyhow!("Invalid nonce length"));
        }
        
        let cipher = XChaCha20Poly1305::new(key.as_bytes().into());
        let nonce = XNonce::from_slice(nonce);

        let plaintext = cipher.decrypt(nonce, ciphertext)
            .map_err(|_| anyhow::anyhow!("Decryption failed (Wrong password or corrupted data)"))?;
        
        Ok(plaintext)
    }
}
```

*lethe_core\src\index.rs*
```
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs::{self, File};
use std::io::{Read, Write};
use std::path::{Path, PathBuf};
use std::time::{SystemTime, UNIX_EPOCH};
use anyhow::{Result, Context};
use crate::crypto::{CryptoEngine, MasterKey};

/// The logical structure of a file inside the vault
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct FileEntry {
    pub path: String,       
    pub size: u64,          
    pub modified: u64,      // Unix timestamp
    pub blocks: Vec<String>,// List of UUIDs: ["uuid1", "uuid2"]

    #[serde(default)] 
    pub is_dir: bool,
}

/// The entire "Database" of the filesystem
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct VaultIndex {
    pub version: u8,
    pub revision: u64,      // Increments on every save (for conflict resolution)
    pub salt: String,       // The salt used for the MasterKey
    pub files: HashMap<String, FileEntry>, // Path -> File Info
}

impl VaultIndex {
    pub fn new(salt: String) -> Self {
        Self {
            version: 1,
            revision: 0,
            salt,
            files: HashMap::new(),
        }
    }
}

/// Manages the loading, saving, and syncing of the Index
#[derive(Debug)]
pub struct IndexManager {
    root_path: PathBuf,
    pub data: VaultIndex,
}

impl IndexManager {
    /// Initialize a manager. 
    /// If index exists on disk, use load() instead.
    pub fn new_empty(path: PathBuf, salt: String) -> Self {
        Self {
            root_path: path,
            data: VaultIndex::new(salt),
        }
    }

    pub fn root_path(&self) -> &PathBuf {
        &self.root_path
    }

    /// Tries to load the index from 3 replicas. 
    /// Picks the one with the highest revision number that successfully decrypts.
    pub fn load(path: PathBuf, key: &MasterKey) -> Result<Self> {
        let mut candidates = Vec::new();

        // Try to load all 3 replicas
        for i in 0..3 {
            let file_path = path.join(format!("meta_{}.bin", i));
            if file_path.exists() {
                if let Ok(index) = Self::read_and_decrypt(&file_path, key) {
                    candidates.push(index);
                }
            }
        }

        if candidates.is_empty() {
            return Err(anyhow::anyhow!("No valid index found. Vault corrupted or wrong password."));
        }

        // Sort by revision (highest first)
        candidates.sort_by(|a, b| b.revision.cmp(&a.revision));
        
        // Pick the winner
        let best_index = candidates.remove(0);
        
        Ok(Self {
            root_path: path,
            data: best_index,
        })
    }

    /// Saves the current index state to all 3 replicas safely.
    pub fn save(&mut self, key: &MasterKey) -> Result<()> {
        self.data.revision += 1; // Increment revision

        // Serialize to CBOR
        let plain_data = serde_cbor::to_vec(&self.data)
            .context("Failed to serialize index")?;

        // Encrypt
        let (encrypted_data, nonce) = CryptoEngine::encrypt(&plain_data, key)?;

        // Write to all 3 replicas
        for i in 0..3 {
            let file_name = format!("meta_{}.bin", i);
            let tmp_name = format!("meta_{}.tmp", i);
            let target_path = self.root_path.join(&file_name);
            let tmp_path = self.root_path.join(&tmp_name);

            // 1. Write to .tmp first (Atomic write pattern)
            let mut file = File::create(&tmp_path)?;
            file.write_all(&nonce)?;
            file.write_all(&encrypted_data)?;
            
            // 2. Rename .tmp to .bin (Atomic replace)
            fs::rename(&tmp_path, &target_path)?;
        }

        Ok(())
    }

    // --- Helper Functions ---

    fn read_and_decrypt(path: &Path, key: &MasterKey) -> Result<VaultIndex> {
        let mut file = File::open(path)?;
        let mut buffer = Vec::new();
        file.read_to_end(&mut buffer)?;

        if buffer.len() < 24 {
            return Err(anyhow::anyhow!("Index file too short"));
        }

        let (nonce, ciphertext) = buffer.split_at(24);
        
        let plain_data = CryptoEngine::decrypt(ciphertext, nonce, key)?;
        
        let index: VaultIndex = serde_cbor::from_slice(&plain_data)?;
        Ok(index)
    }

    pub fn add_file(&mut self, path: String, blocks: Vec<String>, size: u64) {
        let entry = FileEntry {
            path: path.clone(),
            size,
            modified: SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs(),
            blocks,
            is_dir: false,
        };
        self.data.files.insert(path, entry);
    }

    pub fn add_dir(&mut self, path: String) {
        let entry = FileEntry {
            path: path.clone(),
            size: 0,
            modified: SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs(),
            blocks: vec![],
            is_dir: true,
        };
        self.data.files.insert(path, entry);
    }
    
    pub fn get_file(&self, path: &str) -> Option<&FileEntry> {
        self.data.files.get(path)
    }
}
```

*lethe_core\src\lib.rs*
```
pub mod crypto;
pub mod storage;
pub mod index;
pub mod config;

pub use config::VaultConfig;
```

*lethe_core\src\storage.rs*
```
use std::fs::{self, File};
use std::io::{Read, Write};
use std::path::{Path, PathBuf};
use uuid::Uuid;
use anyhow::{Result, Context};
use crate::crypto::{CryptoEngine, MasterKey};

/// Manages the physical storage of encrypted blocks on disk.
#[derive(Debug)]
pub struct BlockManager {
    root_path: PathBuf,
}

impl BlockManager {
    /// Initialize the manager pointing to a specific directory
    pub fn new<P: AsRef<Path>>(path: P) -> Result<Self> {
        let root_path = path.as_ref().to_path_buf();
        
        // Ensure directory exists
        if !root_path.exists() {
            fs::create_dir_all(&root_path)
                .context("Failed to create vault directory")?;
        }
        
        Ok(Self { root_path })
    }

    /// Takes raw data, compresses it, encrypts it, and saves it to disk.
    /// Returns the UUID of the new block.
    pub fn write_block(&self, data: &[u8], key: &MasterKey) -> Result<String> {
        // 1. Compress (Zstd)
        // Level 3 is a good balance of speed vs ratio
        let compressed_data = zstd::stream::encode_all(data, 3)
            .context("Compression failed")?;

        // 2. Encrypt (XChaCha20-Poly1305)
        // Returns (Ciphertext, Nonce)
        let (encrypted_data, nonce) = CryptoEngine::encrypt(&compressed_data, key)?;

        // 3. Generate Random ID
        let block_id = Uuid::new_v4().to_string();
        let file_path = self.root_path.join(format!("blk_{}.bin", block_id));

        // 4. Write to Disk (Nonce + Encrypted Data)
        let mut file = File::create(&file_path)
            .context("Failed to create block file")?;
        
        // We prepend the nonce to the file so we can read it back later
        file.write_all(&nonce)?;
        file.write_all(&encrypted_data)?;

        Ok(block_id)
    }

    /// Reads a block ID, reads disk, decrypts, and decompresses.
    pub fn read_block(&self, block_id: &str, key: &MasterKey) -> Result<Vec<u8>> {
        let file_path = self.root_path.join(format!("blk_{}.bin", block_id));
        
        // 1. Read File
        let mut file = File::open(&file_path)
            .context(format!("Block not found: {}", block_id))?;
        let mut buffer = Vec::new();
        file.read_to_end(&mut buffer)?;

        // 2. Split Nonce (First 24 bytes) and Data
        // XChaCha20 nonce is 24 bytes
        if buffer.len() < 24 {
            return Err(anyhow::anyhow!("Block file corrupted or too short"));
        }
        let (nonce, ciphertext) = buffer.split_at(24);

        // 3. Decrypt
        let compressed_data = CryptoEngine::decrypt(ciphertext, nonce, key)
            .context("Decryption failed (Wrong password or corrupted block)")?;

        // 4. Decompress
        let original_data = zstd::stream::decode_all(compressed_data.as_slice())
            .context("Decompression failed")?;

        Ok(original_data)
    }

    /// Deletes a block permanently
    pub fn delete_block(&self, block_id: &str) -> Result<()> {
        let file_path = self.root_path.join(format!("blk_{}.bin", block_id));
        if file_path.exists() {
            fs::remove_file(file_path).context("Failed to delete block")?;
        }
        Ok(())
    }
}
```